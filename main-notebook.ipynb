{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-20T14:54:17.394092Z",
     "start_time": "2025-07-20T14:53:23.211995Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from utils import set_seed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import shutil"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set seed",
   "id": "1f6ddadecdb6f2ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T14:54:17.551892Z",
     "start_time": "2025-07-20T14:54:17.419117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)"
   ],
   "id": "6a7ec373c23215b5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data handeling",
   "id": "190f73128b873996"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T14:54:18.929681Z",
     "start_time": "2025-07-20T14:54:18.701404Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"./data/train.csv\")",
   "id": "bcb9c65c8f98b004",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T14:54:19.481345Z",
     "start_time": "2025-07-20T14:54:18.945029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_show = []\n",
    "columns = df . columns\n",
    "for i in columns :\n",
    "    types = df[i] . dtypes\n",
    "    unique_data = df[i] . nunique()\n",
    "    NAN_value=df[i].isnull().sum()\n",
    "    duplicated= df.duplicated().sum()\n",
    "\n",
    "    df_show . append ([i , types , unique_data , NAN_value,duplicated])\n",
    "\n",
    "df_info = pd . DataFrame (df_show)\n",
    "df_info . columns =['name of column' , 'types' ,'unique_data' , 'NAN value',\"duplicated\"]\n",
    "\n",
    "df_info.style.highlight_max(color = 'green', axis = 0)"
   ],
   "id": "f3daad5c54b1cf58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c59c0ab010>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fcb02_row0_col1, #T_fcb02_row0_col3, #T_fcb02_row0_col4, #T_fcb02_row1_col0, #T_fcb02_row1_col3, #T_fcb02_row1_col4, #T_fcb02_row2_col3, #T_fcb02_row2_col4, #T_fcb02_row3_col1, #T_fcb02_row3_col2, #T_fcb02_row3_col3, #T_fcb02_row3_col4, #T_fcb02_row4_col1, #T_fcb02_row4_col3, #T_fcb02_row4_col4 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fcb02\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fcb02_level0_col0\" class=\"col_heading level0 col0\" >name of column</th>\n",
       "      <th id=\"T_fcb02_level0_col1\" class=\"col_heading level0 col1\" >types</th>\n",
       "      <th id=\"T_fcb02_level0_col2\" class=\"col_heading level0 col2\" >unique_data</th>\n",
       "      <th id=\"T_fcb02_level0_col3\" class=\"col_heading level0 col3\" >NAN value</th>\n",
       "      <th id=\"T_fcb02_level0_col4\" class=\"col_heading level0 col4\" >duplicated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fcb02_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fcb02_row0_col0\" class=\"data row0 col0\" >image_id</td>\n",
       "      <td id=\"T_fcb02_row0_col1\" class=\"data row0 col1\" >object</td>\n",
       "      <td id=\"T_fcb02_row0_col2\" class=\"data row0 col2\" >3373</td>\n",
       "      <td id=\"T_fcb02_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_fcb02_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcb02_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fcb02_row1_col0\" class=\"data row1 col0\" >width</td>\n",
       "      <td id=\"T_fcb02_row1_col1\" class=\"data row1 col1\" >int64</td>\n",
       "      <td id=\"T_fcb02_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "      <td id=\"T_fcb02_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_fcb02_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcb02_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fcb02_row2_col0\" class=\"data row2 col0\" >height</td>\n",
       "      <td id=\"T_fcb02_row2_col1\" class=\"data row2 col1\" >int64</td>\n",
       "      <td id=\"T_fcb02_row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "      <td id=\"T_fcb02_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_fcb02_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcb02_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fcb02_row3_col0\" class=\"data row3 col0\" >bbox</td>\n",
       "      <td id=\"T_fcb02_row3_col1\" class=\"data row3 col1\" >object</td>\n",
       "      <td id=\"T_fcb02_row3_col2\" class=\"data row3 col2\" >147761</td>\n",
       "      <td id=\"T_fcb02_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_fcb02_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fcb02_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fcb02_row4_col0\" class=\"data row4 col0\" >source</td>\n",
       "      <td id=\"T_fcb02_row4_col1\" class=\"data row4 col1\" >object</td>\n",
       "      <td id=\"T_fcb02_row4_col2\" class=\"data row4 col2\" >7</td>\n",
       "      <td id=\"T_fcb02_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "      <td id=\"T_fcb02_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T14:54:26.250459Z",
     "start_time": "2025-07-20T14:54:19.534526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data.data_loaders import get_all_dataloaders\n",
    "\n",
    "root_dir = './'\n",
    "data_dir = './data/'\n",
    "csv_file = './data/train.csv'\n",
    "\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "img_size = 448\n",
    "learning_rate = 1e-4\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Dataloaders\n",
    "train_loader, aug_loader, val_loader = get_all_dataloaders(\n",
    "    data_dir=data_dir,\n",
    "    csv_file=csv_file,\n",
    "    batch_size=batch_size,\n",
    "    val_split=0.2,\n",
    "    seed=SEED\n",
    ")"
   ],
   "id": "2ef8096188e017a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with 3373 images\n",
      "Total annotations: 147793\n",
      "Dataset initialized with 3373 images\n",
      "Total annotations: 147793\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T14:56:20.534172Z",
     "start_time": "2025-07-20T14:54:26.271482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from model import Yolov1, YOLOv1Loss\n",
    "from train import train\n",
    "# Model\n",
    "model = Yolov1(7, 2, 1).to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = YOLOv1Loss(7, 2, 1)\n",
    "\n",
    "# Train\n",
    "train(model, train_loader, val_loader, optimizer, criterion, epochs, device)"
   ],
   "id": "2c142953409bf59d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 298, in __getitem__\n    return self.dataset[self.indices[idx]]\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PycharmProjects\\dl_wheat_detection_challenge\\data\\wheat_dataset.py\", line 84, in __getitem__\n    sample = self.transforms(\n             ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\composition.py\", line 607, in __call__\n    self.preprocess(data)\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\composition.py\", line 647, in preprocess\n    self._preprocess_processors(data)\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\composition.py\", line 674, in _preprocess_processors\n    processor.preprocess(data)\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\utils.py\", line 245, in preprocess\n    shape = get_shape(data)\n            ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\utils.py\", line 99, in get_shape\n    height, width = get_image_shape(data[\"image\"])\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\utils.py\", line 53, in get_image_shape\n    raise RuntimeError(f\"Unsupported image type: {type(img)}\")\nRuntimeError: Unsupported image type: <class 'NoneType'>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m criterion \u001B[38;5;241m=\u001B[39m YOLOv1Loss(\u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Train\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\dl_wheat_detection_challenge\\train\\train.py:12\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_loader, val_loader, optimizer, criterion, epochs, device)\u001B[0m\n\u001B[0;32m      9\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m     10\u001B[0m loop \u001B[38;5;241m=\u001B[39m tqdm(train_loader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 12\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mloop\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[0;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[0;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1343\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1344\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1345\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1369\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1371\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\_utils.py:644\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    640\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    642\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    643\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 644\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 298, in __getitem__\n    return self.dataset[self.indices[idx]]\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PycharmProjects\\dl_wheat_detection_challenge\\data\\wheat_dataset.py\", line 84, in __getitem__\n    sample = self.transforms(\n             ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\composition.py\", line 607, in __call__\n    self.preprocess(data)\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\composition.py\", line 647, in preprocess\n    self._preprocess_processors(data)\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\composition.py\", line 674, in _preprocess_processors\n    processor.preprocess(data)\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\utils.py\", line 245, in preprocess\n    shape = get_shape(data)\n            ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\utils.py\", line 99, in get_shape\n    height, width = get_image_shape(data[\"image\"])\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\edenkor\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\albumentations\\core\\utils.py\", line 53, in get_image_shape\n    raise RuntimeError(f\"Unsupported image type: {type(img)}\")\nRuntimeError: Unsupported image type: <class 'NoneType'>\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T14:56:20.582648500Z",
     "start_time": "2025-07-20T13:10:42.504405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp=torch.zeros(7,7,11)\n",
    "\n",
    "if not temp[6,6,0]:\n",
    "    print(\"AHHHHHHHHHHHHHHHHHHHHHH\")"
   ],
   "id": "1c6b0be9e6462983",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHHHHHHHHHHHHHHHHHHHHHH\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
